<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Reprodutseeritav andmeanalüüs kasutades R programmi</title>
  <meta name="description" content="Praktilise kursuse ‘Reprodutseeritav andmeanalüüs kasutades R programmi’ materjalid.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Reprodutseeritav andmeanalüüs kasutades R programmi" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Praktilise kursuse ‘Reprodutseeritav andmeanalüüs kasutades R programmi’ materjalid." />
  <meta name="github-repo" content="rstats-tartu/lectures" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Reprodutseeritav andmeanalüüs kasutades R programmi" />
  
  <meta name="twitter:description" content="Praktilise kursuse ‘Reprodutseeritav andmeanalüüs kasutades R programmi’ materjalid." />
  

<meta name="author" content="Taavi Päll, Ülo Maiväli">


<meta name="date" content="2017-09-16">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="jata-meelde.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />








<script src="https://use.fontawesome.com/e4ba4259a1.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Reprodutseeritav andmeanalüüs R programmiga</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Haara kannel, Vanemuine!</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Sissejuhatus</a></li>
<li class="chapter" data-level="3" data-path="tools.html"><a href="tools.html"><i class="fa fa-check"></i><b>3</b> Tarkvaratööriistad</a><ul>
<li class="chapter" data-level="3.1" data-path="tools.html"><a href="tools.html#installeeri-vajalikud-programmid"><i class="fa fa-check"></i><b>3.1</b> Installeeri vajalikud programmid</a></li>
<li class="chapter" data-level="3.2" data-path="tools.html"><a href="tools.html#loo-githubi-konto"><i class="fa fa-check"></i><b>3.2</b> Loo GitHubi konto</a></li>
<li class="chapter" data-level="3.3" data-path="tools.html"><a href="tools.html#loo-uus-r-projekt"><i class="fa fa-check"></i><b>3.3</b> Loo uus R projekt</a></li>
<li class="chapter" data-level="3.4" data-path="tools.html"><a href="tools.html#git-merge-konfliktid"><i class="fa fa-check"></i><b>3.4</b> Git <em>Merge</em> konfliktid</a></li>
<li class="chapter" data-level="3.5" data-path="tools.html"><a href="tools.html#r-projekti-kataloogi-soovitatav-minimaalne-struktuur"><i class="fa fa-check"></i><b>3.5</b> R projekti kataloogi soovitatav minimaalne struktuur</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="pakettide-installeerimine.html"><a href="pakettide-installeerimine.html"><i class="fa fa-check"></i><b>4</b> Pakettide installeerimine</a><ul>
<li class="chapter" data-level="4.1" data-path="pakettide-installeerimine.html"><a href="pakettide-installeerimine.html#r-repositooriumid"><i class="fa fa-check"></i><b>4.1</b> R repositooriumid</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html"><i class="fa fa-check"></i><b>5</b> R on kalkulaator</a><ul>
<li class="chapter" data-level="5.1" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#r-objektid"><i class="fa fa-check"></i><b>5.1</b> R objektid</a><ul>
<li class="chapter" data-level="5.1.1" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#objekt-ja-nimi"><i class="fa fa-check"></i><b>5.1.1</b> Objekt ja nimi</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#objektide-tuubid"><i class="fa fa-check"></i><b>5.2</b> Objektide tüübid</a><ul>
<li class="chapter" data-level="5.2.1" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#vektor---andmerida"><i class="fa fa-check"></i><b>5.2.1</b> Vektor - andmerida</a></li>
<li class="chapter" data-level="5.2.2" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#uus-vektor-seq-ja-rep"><i class="fa fa-check"></i><b>5.2.2</b> Uus vektor: <code>seq()</code> ja <code>rep()</code></a></li>
<li class="chapter" data-level="5.2.3" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#tehted-arvuliste-vektoritega"><i class="fa fa-check"></i><b>5.2.3</b> tehted arvuliste vektoritega</a></li>
<li class="chapter" data-level="5.2.4" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#list-andmekott"><i class="fa fa-check"></i><b>5.2.4</b> List – andmekott</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#tibble-ja-data-frame---andmeraamid"><i class="fa fa-check"></i><b>5.3</b> Tibble ja data frame - andmeraamid</a><ul>
<li class="chapter" data-level="5.3.1" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#uhendame-kaks-tibblet-rea-kaupa"><i class="fa fa-check"></i><b>5.3.1</b> Ühendame kaks tibblet rea kaupa</a></li>
<li class="chapter" data-level="5.3.2" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#andmeraamide-salvestamine-eksport-import"><i class="fa fa-check"></i><b>5.3.2</b> Andmeraamide salvestamine (eksport-import)</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#tabelit-sisse-lugedes-vaata-ule-na-d"><i class="fa fa-check"></i><b>5.4</b> tabelit sisse lugedes vaata üle NA-d</a><ul>
<li class="chapter" data-level="5.4.1" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#matrix---numbriraam"><i class="fa fa-check"></i><b>5.4.1</b> 4. Matrix - numbriraam</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#andmete-tuubid"><i class="fa fa-check"></i><b>5.5</b> Andmete tüübid</a></li>
<li class="chapter" data-level="5.6" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#indekseerimine"><i class="fa fa-check"></i><b>5.6</b> Indekseerimine</a><ul>
<li class="chapter" data-level="5.6.1" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#vektorid-ja-nende-indeksid-on-uhe-dimensionaalsed"><i class="fa fa-check"></i><b>5.6.1</b> Vektorid ja nende indeksid on ühe-dimensionaalsed</a></li>
<li class="chapter" data-level="5.6.2" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#andmeraamid-ja-maatriksid-on-kahe-dimensionaalsed-nagu-ka-nende-indeksid"><i class="fa fa-check"></i><b>5.6.2</b> andmeraamid ja maatriksid on kahe-dimensionaalsed, nagu ka nende indeksid</a></li>
<li class="chapter" data-level="5.6.3" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#litside-indeksid-on-kolme-dimensionaalsed"><i class="fa fa-check"></i><b>5.6.3</b> litside indeksid on kolme-dimensionaalsed</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#regular-expression-ja-find-replace"><i class="fa fa-check"></i><b>5.7</b> Regular expression ja find &amp; replace</a></li>
<li class="chapter" data-level="5.8" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#tidyverse"><i class="fa fa-check"></i><b>5.8</b> Tidyverse</a><ul>
<li class="chapter" data-level="5.8.1" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#tidy-tabeli-struktuur"><i class="fa fa-check"></i><b>5.8.1</b> Tidy tabeli struktuur</a></li>
<li class="chapter" data-level="5.8.2" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#tabeli-dimensioonide-muutmine-pikk-ja-lai-formaat"><i class="fa fa-check"></i><b>5.8.2</b> Tabeli dimensioonide muutmine (pikk ja lai formaat)</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#dplyr-i-5-verbi"><i class="fa fa-check"></i><b>5.9</b> dplyr-i 5 verbi</a><ul>
<li class="chapter" data-level="5.9.1" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#select-columns"><i class="fa fa-check"></i><b>5.9.1</b> <code>select()</code> columns</a></li>
<li class="chapter" data-level="5.9.2" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#filter-rows"><i class="fa fa-check"></i><b>5.9.2</b> <code>filter()</code> rows</a></li>
<li class="chapter" data-level="5.9.3" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#summarise"><i class="fa fa-check"></i><b>5.9.3</b> <code>summarise()</code></a></li>
<li class="chapter" data-level="5.9.4" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#group_by"><i class="fa fa-check"></i><b>5.9.4</b> <code>group_by()</code></a></li>
<li class="chapter" data-level="5.9.5" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#mutate"><i class="fa fa-check"></i><b>5.9.5</b> 5. mutate</a></li>
<li class="chapter" data-level="5.9.6" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#grouped-filters"><i class="fa fa-check"></i><b>5.9.6</b> Grouped filters</a></li>
<li class="chapter" data-level="5.9.7" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#separate-one-column-into-several"><i class="fa fa-check"></i><b>5.9.7</b> <code>separate()</code> one column into several</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#faktorid"><i class="fa fa-check"></i><b>5.10</b> Faktorid</a><ul>
<li class="chapter" data-level="5.10.1" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#fct_recode-rekodeerib-faktori-tasemed"><i class="fa fa-check"></i><b>5.10.1</b> <code>fct_recode()</code> rekodeerib faktori tasemed</a></li>
<li class="chapter" data-level="5.10.2" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#fct_collapse-annab-argumenti-sisse-vanade-tasemete-vektori-et-teha-vahem-uusi-tasemeid."><i class="fa fa-check"></i><b>5.10.2</b> <code>fct_collapse()</code> annab argumenti sisse vanade tasemete vektori, et teha vähem uusi tasemeid.</a></li>
<li class="chapter" data-level="5.10.3" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#fct_lump-loob-kokku-koik-vahem-arv-kordi-esinevad-tasemed."><i class="fa fa-check"></i><b>5.10.3</b> <code>fct_lump()</code> lööb kokku kõik vähem arv kordi esinevad tasemed.</a></li>
<li class="chapter" data-level="5.10.4" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#rekodeerime-pideva-muutuja-faktoriks"><i class="fa fa-check"></i><b>5.10.4</b> Rekodeerime pideva muutuja faktoriks</a></li>
<li class="chapter" data-level="5.10.5" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#muudame-faktori-tasemete-jarjekorda-joonisel"><i class="fa fa-check"></i><b>5.10.5</b> Muudame faktori tasemete järjekorda joonisel</a></li>
<li class="chapter" data-level="5.10.6" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#fct_relevel-tostab-joonisel-osad-tasemed-teistest-ettepoole"><i class="fa fa-check"></i><b>5.10.6</b> <code>fct_relevel()</code> tõstab joonisel osad tasemed teistest ettepoole</a></li>
<li class="chapter" data-level="5.10.7" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#joontega-plotil-saab-fct_reorder2-abil-assotseerida-y-vaartused-suurimate-x-vaartustega"><i class="fa fa-check"></i><b>5.10.7</b> Joontega plotil saab <code>fct_reorder2()</code> abil assotseerida y väärtused suurimate x väärtustega</a></li>
<li class="chapter" data-level="5.10.8" data-path="r-on-kalkulaator.html"><a href="r-on-kalkulaator.html#tulpdiagrammide-korral-kasuta-fct_infreq"><i class="fa fa-check"></i><b>5.10.8</b> Tulpdiagrammide korral kasuta <code>fct_infreq()</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="funs.html"><a href="funs.html"><i class="fa fa-check"></i><b>6</b> R on andmeanalüüsi keel, mille verbid on funktsioonid</a><ul>
<li class="chapter" data-level="6.1" data-path="funs.html"><a href="funs.html#kirjutame-oma-esimese-r-funktsiooni"><i class="fa fa-check"></i><b>6.1</b> Kirjutame oma esimese R funktsiooni</a></li>
<li class="chapter" data-level="6.2" data-path="funs.html"><a href="funs.html#funktsioonide-raamatukogud"><i class="fa fa-check"></i><b>6.2</b> Funktsioonide raamatukogud</a></li>
<li class="chapter" data-level="6.3" data-path="funs.html"><a href="funs.html#paiguta-koigi-raamatukogude-lugemine-koodi-algusesse"><i class="fa fa-check"></i><b>6.3</b> Paiguta kõigi raamatukogude lugemine koodi algusesse</a></li>
<li class="chapter" data-level="6.4" data-path="funs.html"><a href="funs.html#hurraa-uus-arvuti-aga-mis-libraryd-mul-olid"><i class="fa fa-check"></i><b>6.4</b> Hurraa, uus arvuti! aga mis libraryd mul olid…</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliograafia.html"><a href="bibliograafia.html"><i class="fa fa-check"></i>Bibliograafia</a></li>
<li class="chapter" data-level="7" data-path="bayesiaanlik-statistika.html"><a href="bayesiaanlik-statistika.html"><i class="fa fa-check"></i><b>7</b> Bayesiaanlik statistika</a><ul>
<li class="chapter" data-level="7.1" data-path="bayesiaanlik-statistika.html"><a href="bayesiaanlik-statistika.html#ajaloost-ja-toenaosusest"><i class="fa fa-check"></i><b>7.1</b> Ajaloost ja tõenäosusest</a><ul>
<li class="chapter" data-level="7.1.1" data-path="bayesiaanlik-statistika.html"><a href="bayesiaanlik-statistika.html#naide-kahe-grupi-vordlus"><i class="fa fa-check"></i><b>7.1.1</b> Näide: kahe grupi võrdlus</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="osa-mudel-ja-maailm.html"><a href="osa-mudel-ja-maailm.html"><i class="fa fa-check"></i><b>8</b> 1. osa: Mudel ja maailm</a><ul>
<li class="chapter" data-level="8.0.1" data-path="osa-mudel-ja-maailm.html"><a href="osa-mudel-ja-maailm.html#suur-ja-vaike-maailm"><i class="fa fa-check"></i><b>8.0.1</b> Suur ja väike maailm</a></li>
<li class="chapter" data-level="8.0.2" data-path="osa-mudel-ja-maailm.html"><a href="osa-mudel-ja-maailm.html#mudeli-vaike-maailm"><i class="fa fa-check"></i><b>8.0.2</b> Mudeli väike maailm</a></li>
<li class="chapter" data-level="8.0.3" data-path="osa-mudel-ja-maailm.html"><a href="osa-mudel-ja-maailm.html#millest-koosneb-mudel"><i class="fa fa-check"></i><b>8.0.3</b> Millest koosneb mudel?</a></li>
<li class="chapter" data-level="8.0.4" data-path="osa-mudel-ja-maailm.html"><a href="osa-mudel-ja-maailm.html#moistet"><i class="fa fa-check"></i><b>8.0.4</b> 4 mõistet</a></li>
<li class="chapter" data-level="8.0.5" data-path="osa-mudel-ja-maailm.html"><a href="osa-mudel-ja-maailm.html#mudeli-fittimine"><i class="fa fa-check"></i><b>8.0.5</b> Mudeli fittimine</a></li>
<li class="chapter" data-level="8.0.6" data-path="osa-mudel-ja-maailm.html"><a href="osa-mudel-ja-maailm.html#veamudel"><i class="fa fa-check"></i><b>8.0.6</b> Veamudel</a></li>
<li class="chapter" data-level="8.0.7" data-path="osa-mudel-ja-maailm.html"><a href="osa-mudel-ja-maailm.html#statistiline-mudel-koosneb-3-komponendist"><i class="fa fa-check"></i><b>8.0.7</b> Statistiline mudel koosneb 3 komponendist:</a></li>
<li class="chapter" data-level="8.0.8" data-path="osa-mudel-ja-maailm.html"><a href="osa-mudel-ja-maailm.html#normaaljaotuse-ja-lognormaaljaotuse-erilisus"><i class="fa fa-check"></i><b>8.0.8</b> normaaljaotuse ja lognormaaljaotuse erilisus</a></li>
<li class="chapter" data-level="8.1" data-path="osa-mudel-ja-maailm.html"><a href="osa-mudel-ja-maailm.html#kusimused-mida-statistika-kusib"><i class="fa fa-check"></i><b>8.1</b> Küsimused, mida statistika küsib</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="osa-kuidas-naevad-valja-teie-andmed.html"><a href="osa-kuidas-naevad-valja-teie-andmed.html"><i class="fa fa-check"></i><b>9</b> 2 osa. Kuidas näevad välja teie andmed?</a><ul>
<li class="chapter" data-level="9.1" data-path="osa-kuidas-naevad-valja-teie-andmed.html"><a href="osa-kuidas-naevad-valja-teie-andmed.html#summaarsed-statistikud"><i class="fa fa-check"></i><b>9.1</b> summaarsed statistikud</a><ul>
<li class="chapter" data-level="9.1.1" data-path="osa-kuidas-naevad-valja-teie-andmed.html"><a href="osa-kuidas-naevad-valja-teie-andmed.html#keskvaartused"><i class="fa fa-check"></i><b>9.1.1</b> keskväärtused</a></li>
<li class="chapter" data-level="9.1.2" data-path="osa-kuidas-naevad-valja-teie-andmed.html"><a href="osa-kuidas-naevad-valja-teie-andmed.html#muutuja-sisene-varieeruvus"><i class="fa fa-check"></i><b>9.1.2</b> muutuja sisene varieeruvus</a></li>
<li class="chapter" data-level="9.1.3" data-path="osa-kuidas-naevad-valja-teie-andmed.html"><a href="osa-kuidas-naevad-valja-teie-andmed.html#muutujate-koos-varieeruvus"><i class="fa fa-check"></i><b>9.1.3</b> muutujate koos-varieeruvus</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="osa-kuidas-naevad-valja-teie-andmed.html"><a href="osa-kuidas-naevad-valja-teie-andmed.html#eda-eksploratoorne-andmeanaluus"><i class="fa fa-check"></i><b>9.2</b> 2.2 EDA — eksploratoorne andmeanalüüs</a><ul>
<li class="chapter" data-level="9.2.1" data-path="osa-kuidas-naevad-valja-teie-andmed.html"><a href="osa-kuidas-naevad-valja-teie-andmed.html#kuidas-uurida-muutuja-sisest-varieeruvust"><i class="fa fa-check"></i><b>9.2.1</b> Kuidas uurida muutuja sisest varieeruvust</a></li>
<li class="chapter" data-level="9.2.2" data-path="osa-kuidas-naevad-valja-teie-andmed.html"><a href="osa-kuidas-naevad-valja-teie-andmed.html#kahe-muutuja-koos-varieerumine"><i class="fa fa-check"></i><b>9.2.2</b> Kahe muutuja koos-varieerumine</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="osa-kuidas-naevad-valja-teie-andmed.html"><a href="osa-kuidas-naevad-valja-teie-andmed.html#joongraafikud"><i class="fa fa-check"></i><b>9.3</b> Joongraafikud</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="jata-meelde.html"><a href="jata-meelde.html"><i class="fa fa-check"></i><b>10</b> Jäta meelde:</a><ul>
<li class="chapter" data-level="10.1" data-path="jata-meelde.html"><a href="jata-meelde.html#sonastik"><i class="fa fa-check"></i><b>10.1</b> Sõnastik</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html"><i class="fa fa-check"></i><b>11</b> Järeldav statistika</a><ul>
<li class="chapter" data-level="11.0.1" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#simulatsiooni-joud"><i class="fa fa-check"></i><b>11.0.1</b> 3.1. Simulatsiooni jõud</a></li>
<li class="chapter" data-level="11.0.2" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#valim-ei-ole-sama-mis-populatsioon"><i class="fa fa-check"></i><b>11.0.2</b> 3.1.1. Valim ei ole sama, mis populatsioon</a></li>
<li class="chapter" data-level="11.0.3" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#bootstrappimine"><i class="fa fa-check"></i><b>11.0.3</b> 3.1.2. Bootstrappimine</a></li>
<li class="chapter" data-level="11.1" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#bayesi-pohimote"><i class="fa fa-check"></i><b>11.1</b> 3.2. Bayesi põhimõte</a><ul>
<li class="chapter" data-level="11.1.1" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#naide"><i class="fa fa-check"></i><b>11.1.1</b> 1. näide</a></li>
<li class="chapter" data-level="11.1.2" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#naide-sonastame-oma-probleemi-umber"><i class="fa fa-check"></i><b>11.1.2</b> 2. näide: sõnastame oma probleemi ümber</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#mudelite-keel"><i class="fa fa-check"></i><b>11.2</b> 2.3. Mudelite keel</a><ul>
<li class="chapter" data-level="11.2.1" data-path="jareldav-statistika.html"><a href="jareldav-statistika.html#beta-prior"><i class="fa fa-check"></i><b>11.2.1</b> beta prior</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstats-tartu/lectures" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Reprodutseeritav andmeanalüüs kasutades R programmi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="jareldav-statistika" class="section level1">
<h1><span class="header-section-number">11</span> Järeldav statistika</h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(bayesboot)
<span class="kw">library</span>(boot)
<span class="kw">library</span>(rethinking) <span class="co">#HPDI() and PI(). Requires Stan.</span>
<span class="co">#source(&quot;R/&quot;)</span></code></pre></div>
<div id="simulatsiooni-joud" class="section level3">
<h3><span class="header-section-number">11.0.1</span> 3.1. Simulatsiooni jõud</h3>
<p>Järeldav statistika püüab valimi põhjal teha järeldusi statistilise populatsiooni kohta, millest see valim pärineb. Sellisel tegevusel on mõtet ainult siis, kui ühest küljest valim peegeldab populatsiooni ja teisest küljest valim ei ole sama asi, mis populatsioon. Seega on statistika abil tehtud järeldused alati rohkem või vähem ebamäärased ning meil on vaja meetodit selle ebamäärasuse mõõtmiseks. Aga kõigepealt illustreerime valimi ja populatsiooni erinevust.</p>
</div>
<div id="valim-ei-ole-sama-mis-populatsioon" class="section level3">
<h3><span class="header-section-number">11.0.2</span> 3.1.1. Valim ei ole sama, mis populatsioon</h3>
<p>Simuleerimine on lahe sest erinevalt päris maailmast elavad simulatsioonid mudeli väikses maailmas ning seega teame me täpselt, mida me teeme ja mida on meil selle tagajärjel oodata. Simulatsioonidega saame me hõlpsalt kontrollida, kas ja kuidas meie mudelid töötavad ning genereerida olukordi (parameetrite väärtuste kombinatsioone), mida päris maailmas kunagi ette ei tule. Selles mõttes on mudelid korraga nii väiksemad kui suuremad kui päris maailm.</p>
<p>Alustuseks simuleerime juhuvalimi n=3 lõpmata suurest normaaljaotusega populatsioonist, mille keskmine on 100 ja sd on 20. Päris elus on korraliku juhuvalimi tõmbamine tehniliselt tõsine ettevõtmine ja, mis veelgi olulisem, me ei tea kunagi, milline on populatsiooni tõeline jaotus, keskmine ja sd. Elagu simulatsioon!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>) <span class="co">#makes random number generation reproducible</span>
(Sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">3</span>, <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">20</span>)) <span class="co">#extra parentheses work as print()</span></code></pre></div>
<pre><code>## [1]  87.47092 103.67287  83.28743</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(Sample)</code></pre></div>
<pre><code>## [1] 91.47707</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(Sample)</code></pre></div>
<pre><code>## [1] 10.76701</code></pre>
<p>Nagu näha on meie valimi keskmine 10% väiksem kui peaks ja valimi sd lausa kaks korda väiksem kui peaks. Seega peegeldab meie valim halvasti populatsiooni — aga me teame seda ainult tänu sellele, et tegu on simulatsiooniga.</p>
<p>Kui juba simuleerida, siis robinal: tõmbame ühe valimi asemel 10 000, arvutame seejärel 10 000 keskmist ja sd-d ning vaatame omakorda nende statistikute jaotusi ja keskväärtusi. Simulatsioon on nagu tselluliit — see on nii odav, et igaüks võib seda endale lubada.</p>
<p>Meie lootus on, et kui meil on palju valimeid, millel kõigil on juhuslik viga, mis neid populatsiooni suhtes ühele või teisele poole kallutab, siis rohkem on valimeid, mis asuvad tõelisele populatsioonile pigem lähemal kui kaugemal.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N &lt;-<span class="st"> </span><span class="dv">3</span>
N_simulations &lt;-<span class="st"> </span><span class="dv">10000</span>
df &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">a =</span> <span class="kw">rnorm</span>(N <span class="op">*</span><span class="st"> </span>N_simulations, <span class="dv">100</span>, <span class="dv">20</span>), <span class="dt">b =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>N_simulations, <span class="dt">each =</span> N) )
Summary &lt;-<span class="st">  </span>df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(b) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">Mean=</span><span class="kw">mean</span>(a), <span class="dt">SD=</span> <span class="kw">sd</span>(a) ) 

Summary <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Mean) ) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>()</code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="main_files/figure-html/unnamed-chunk-187-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(Summary<span class="op">$</span>Mean) </code></pre></div>
<pre><code>## [1] 99.98043</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(Summary<span class="op">$</span>SD)</code></pre></div>
<pre><code>## [1] 17.76452</code></pre>
<p>Oh-hooo. Paljude valimite keskmiste keskmine ennustab väga täpselt populatsiooni keskmist aga sd-de keskmise keskmine alahindab populatsiooni sd-d. Valem, millega sd-d arvutatakse tõõtab lihtsalt kallutatult, kui n on väike (&lt;10)</p>
<p>Ja nüüd 10 000 SD keskväärtused:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Summary <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(SD)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>()</code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="main_files/figure-html/unnamed-chunk-189-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mode &lt;-<span class="st">  </span><span class="cf">function</span>(x, <span class="dt">adjust=</span><span class="dv">1</span>) {
  x &lt;-<span class="st"> </span><span class="kw">na.omit</span>(x)
  dx &lt;-<span class="st"> </span><span class="kw">density</span>(x, <span class="dt">adjust=</span>adjust)
y_max &lt;-<span class="st"> </span>dx<span class="op">$</span>x[<span class="kw">which.max</span>(dx<span class="op">$</span>y)] 
y_max
}
<span class="kw">mode</span>(Summary<span class="op">$</span>SD)</code></pre></div>
<pre><code>## [1] 14.07554</code></pre>
<p>SD-de jaotus on ebasümmeetriline ja mood ehk kõige tõenäolisem valimi sd väärtus, mida võiksime oodata, on u 14, samal ajal kui populatsiooni sd = 20. Lisaks on sd-de jaotusel paks saba, mis tagab, et tesest küljest pole ka vähetõenäoline, et meie valimi sd populatsiooni sd-d kõvasti üle hindab.</p>
<p>Arvutame, mitu % valimite sd-e keskmistest on &gt; 25</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(Summary<span class="op">$</span>SD<span class="op">&gt;</span><span class="dv">25</span>)<span class="op">/</span><span class="dv">10000</span></code></pre></div>
<pre><code>## [1] 0.2114</code></pre>
<p>Me saame &gt;20% tõenäosusega pahasti ülehinnatud SD.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(Summary<span class="op">$</span>SD<span class="op">&lt;</span><span class="dv">15</span>)<span class="op">/</span><span class="dv">10000</span></code></pre></div>
<pre><code>## [1] 0.4344</code></pre>
<p>Ja me saame &gt;40% tõenäosusega pahasti alahinnatud sd. Selline on väikeste valimite traagika. (Jooksuta sama simulatsiooni n = 100 korral.)</p>
<p>Aga vähemalt populatsiooni keskmise saame me palju valimeid tõmmates ilusasti kätte — ka väga väikeste valimitega.</p>
<p>Kahjuks pole meil ei vahendeid ega kannatust 10 000 valimi loodusest kogumiseks. Enamasti on meil üksainus valim. Õnneks pole sellest väga hullu sest meil on olemas analoogne meetod, mis töötab üsna hästi ka ühe valimiga. Seda kutsutakse <em>bootstrappimiseks</em> ja selle võttis esimesena kasutusele parun von Münchausen. Too jutukas parun nimelt suutis end soomülkast iseenda patsi pidi välja tõmmata, mis ongi bootstrappimise põhimõte.</p>
</div>
<div id="bootstrappimine" class="section level3">
<h3><span class="header-section-number">11.0.3</span> 3.1.2. Bootstrappimine</h3>
<blockquote>
<p>Populatsioon on valimile, mis valim on bootstrappitud valimile.</p>
</blockquote>
<p>Nüüd alustame ühestainsast empiirilisest valimist ja genereerime sellest 10 000 virtuaalset valimit. Selleks tõmbame me oma valimist virtuaalselt 10 000 uut juhuvalimit (bootstrap valimit), igaüks neist sama suur kui algne valim. Trikk seisneb selles, et bootstrap valimite tõmbamine käib asendusega, st iga empiirilise valimi element, mis bootstrap valimisse tõmmatakse, pannakse kohe ka algsesse valimisse tagasi. Seega saab seda elementi kohe uuesti samasse bootstrap valimisse tõmmata (kui juhus nii tahab). Seega sisaldab tüüpiline bootstrap valim osasid algse valimi numbreid mitmes korduses ja teisi üldse mitte. Bootstrap valimid plotitakse sama moodi nagu me ennist tegime oma valimitega lõpmatust populatsioonist. Ainsad erinevused on, et bootstrapis on piiratud algse andmekogu suurus, millest valimeid tõmmatakse ning, et iga bootstrapi valim on sama suur kui algne andmekogu.</p>
<p>Bootstrap empiirilisele valimile suurusega n töötab nii:</p>
<ol style="list-style-type: decimal">
<li>tõmba empiirilisest valimist k uut virtuaalset valimit, igaüks suurusega n</li>
<li>arvuta keskmine, sd või mistahes muu statistik igale bootstrapi valimile. Tee seda k korda.</li>
<li>joonista oma statistiku väärtustest histogramm või density plot</li>
<li>nende andmete põhjal saab küsida palju toreidaid küsimusi — vt allpool.</li>
</ol>
<p>Mis on USA presidentide keskmine pikkus? Meil on valim 10 presidendi pikkusega.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">heights &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">183</span>, <span class="dv">192</span>, <span class="dv">182</span>, <span class="dv">183</span>, <span class="dv">177</span>, <span class="dv">185</span>, <span class="dv">188</span>, <span class="dv">188</span>, <span class="dv">182</span>, <span class="dv">185</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>(heights) </code></pre></div>
<pre><code>## Warning in as.data.frame.numeric(value, stringsAsFactors = FALSE, ...):
## &#39;row.names&#39; is not a character vector of length 10 -- omitting it. Will be
## an error!</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">10</span> <span class="co">#sample size</span>
nr_boot_samples &lt;-<span class="st"> </span><span class="dv">4000</span> <span class="co">#the nr of bootstrap samples</span>
a &lt;-<span class="st"> </span><span class="kw">sample_n</span>(heights, n <span class="op">*</span><span class="st"> </span>nr_boot_samples, <span class="dt">replace=</span><span class="ot">TRUE</span>)  <span class="co">#create random sample with replacement</span>
a<span class="op">$</span>key &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>nr_boot_samples, <span class="dt">each =</span> n) <span class="co">#create a column &quot;key&quot; that cuts the sample into slices of size n</span>
a1 &lt;-<span class="st"> </span>a <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">Value=</span> <span class="kw">mean</span>(value)) <span class="co">#calculate the mean for each slice of n values</span>
<span class="kw">dens</span>(a1<span class="op">$</span>Value)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-193-1.png" width="672" /></p>
<p>Alternatiivne ja aeglasem kood, mis kasutab mosaic::do().</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mosaic)</code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;lattice&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:boot&#39;:
## 
##     melanoma</code></pre>
<pre><code>## Loading required package: ggformula</code></pre>
<pre><code>## 
## New to ggformula?  Try the tutorials: 
##  learnr::run_tutorial(&quot;introduction&quot;, package = &quot;ggformula&quot;)
##  learnr::run_tutorial(&quot;refining&quot;, package = &quot;ggformula&quot;)</code></pre>
<pre><code>## 
## Attaching package: &#39;ggformula&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:modelr&#39;:
## 
##     na.warn</code></pre>
<pre><code>## Loading required package: mosaicData</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:tidyr&#39;:
## 
##     expand</code></pre>
<pre><code>## 
## The &#39;mosaic&#39; package masks several functions from core packages in order to add 
## additional features.  The original behavior of these functions should not be affected by this.
## 
## Note: If you use the Matrix package, be sure to load it BEFORE loading mosaic.</code></pre>
<pre><code>## 
## Attaching package: &#39;mosaic&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:Matrix&#39;:
## 
##     mean</code></pre>
<pre><code>## The following object is masked from &#39;package:boot&#39;:
## 
##     logit</code></pre>
<pre><code>## The following object is masked from &#39;package:brms&#39;:
## 
##     mm</code></pre>
<pre><code>## The following object is masked from &#39;package:modelr&#39;:
## 
##     resample</code></pre>
<pre><code>## The following objects are masked from &#39;package:psych&#39;:
## 
##     logit, read.file, rescale</code></pre>
<pre><code>## The following object is masked from &#39;package:ggthemes&#39;:
## 
##     theme_map</code></pre>
<pre><code>## The following objects are masked from &#39;package:rethinking&#39;:
## 
##     logit, resample</code></pre>
<pre><code>## The following objects are masked from &#39;package:car&#39;:
## 
##     deltaMethod, logit</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     count, do, tally</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     cross</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     binom.test, cor, cor.test, cov, fivenum, IQR, median,
##     prop.test, quantile, sd, t.test, var</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     max, mean, min, prod, range, sample, sum</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">heights &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">183</span>, <span class="dv">192</span>, <span class="dv">182</span>, <span class="dv">183</span>, <span class="dv">177</span>, <span class="dv">185</span>, <span class="dv">188</span>, <span class="dv">188</span>, <span class="dv">182</span>, <span class="dv">185</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>(heights) </code></pre></div>
<pre><code>## Warning in as.data.frame.numeric(value, stringsAsFactors = FALSE, ...):
## &#39;row.names&#39; is not a character vector of length 10 -- omitting it. Will be
## an error!</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sample_means &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">4000</span>) <span class="op">*</span>
<span class="st">    </span>(heights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)) </code></pre></div>
<pre><code>## Using parallel package.
##   * Set seed with set.rseed().
##   * Disable this message with options(`mosaic:parallelMessage` = FALSE)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#võta heigths andmeraamist 10-ne valim (tagasi panekuga) ja tee seda 4000 korda järjest. tulemuseks on tidy tibble, kus on veerg .index, mille järgi saab grupeerida.</span>

sample_means1 &lt;-<span class="st"> </span>sample_means <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(.index) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">Mean=</span><span class="kw">mean</span>(value))
    
<span class="kw">ggplot</span>(<span class="dt">data =</span> sample_means1, <span class="kw">aes</span>(<span class="dt">x =</span> Mean)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">bins =</span> <span class="dv">20</span>)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-194-1.png" width="672" /></p>
<p>Nii saab do() abil 2 veeruga tibble, mille igas veerus on 3 juhuslikku arvu. NB! kuna ka tidyverse/dplyr sisaldab do() nimelist funktsiooni, on kasulik seda siin eksplitsiitselt mosaic::do() kaudu esile manada.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">3</span>)<span class="op">*</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">2</span>)</code></pre></div>
<pre><code>## Using parallel package.
##   * Set seed with set.rseed().
##   * Disable this message with options(`mosaic:parallelMessage` = FALSE)</code></pre>
<pre><code>##           V1          V2
## 1  2.1831575  0.10281544
## 2  0.8128593 -0.06289664
## 3 -0.3278966  1.40192887</code></pre>
<p>Mida selline keskväärtuste jaotus tähendab? Me võime seda vaadelda posterioorse tõenäosusjaotusena. Selle tõlgenduse kohaselt iseloomustab see jaotus täpselt meie usku presidentide keskmise pikkuse kohta, niipalju kui see usk põhineb bootstrappimises kasutatud andmetel. Senikaua, kui meil pole muid relevantseid andmeid, on kõik, mida me usume teadvat USA presidentide keskmise pikkuse kohta, peidus selles jaotuses. Need pikkused, mille kohal jaotus on kõrgem, sisaldavad meie jaoks tõenäolisemalt tegelikku USA presidentide keskmist pikkust kui need pikkused, mille kohal posterioorne jaotus on madalam.</p>
<p>Kuidas selle jaotusega edasi töötada? See on lihtne: meil on 4000 arvu ja me teeme nendega kõike seda, mida parasjagu tahame.</p>
<p>Näiteks me võime arvutada, millisesse pikkuste vahemikku jääb 92% meie usust USA presidentide tõelise keskmise pikkuse kohta. See tähendab, et teades seda vahemikku peaksime olema valmis maksma mitte rohkem kui 92 senti pileti eest, mis juhul kui USA presidentide keskmine pikkus tõesti jääb sinna vahemikku, toob meile võidu suuruses 1 EUR (ja 8 senti kasumit). Selline kihlveokontor on muide täiesti respektaabel ja akadeemiline tõenäosuse tõlgendus; see on paljude arvates lausa parim tõlgendus, mis meil on.</p>
<p>Miks just 92% usaldusinterval? Vastus on, et miks mitte? Meil pole ühtegi universaalset põhjust eelistada üht usaldusvahemiku suurust teisele. Olgu meil usaldusinteval 90%, 92% või 95% — tõlgendus on ikka sama. Nimelt, et me usume, et suure tõenäosusega jääb tegelik keskväärtus meie poolt arvutatud vahemikku. Mudeli ja maailma erinevused tingivad niikuinii selle, et konkreetne number ei kandu mudelist üle pärismaailma. NB! pane tähele, et eelnevalt mainitud kihlveokontor töötab mudeli maailmas, mitte teie kodu lähedasel hipodroomil.</p>
<p>92% usaldusintervalli arvutamiseks on kaks meetodit, mis enamasti annavad vaid veidi erinevaid tulemusi. 1) HPDI — Highest Density Probability Interval — alustab jaotuse tipust (tippudest) ja isoleerib 92% jaotuse kõrgema(te) osa(de) pindalast 2) PI — Probability Interval — alustab jaotuse servadest ja isoleerib kummagist servast 4% jaotuse pindalast. See on sama, mis arvutada 4% ja 96% kvantiilid</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">HPDI</span>(a1<span class="op">$</span>Value, <span class="dt">prob=</span><span class="fl">0.92</span>) <span class="co">#highest probability density interval - non-symmetric</span></code></pre></div>
<pre><code>## |0.92 0.92| 
## 182.3 186.6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">PI</span>(a1<span class="op">$</span>Value, <span class="dt">prob=</span><span class="fl">0.92</span>) <span class="co">#symmetric method.</span></code></pre></div>
<pre><code>##    4%   96% 
## 182.3 186.7</code></pre>
<p>HPDI on üldiselt parem mõõdik kui PI, aga teatud juhtudel on seda raskem arvutada. Kui HPDI ja PI tugevalt erinevad, on hea mõte piirduda jaotuse enda avaldamisega — jaotus ise sisaldab kogu informatsiooni, mis meil on oma statistiku väärtuse kohta. Intervallid on lihtsalt summaarsed statistikud andmete kokkuvõtlikuks esitamiseks.</p>
<p>Kui suure tõenäosusega on USA presidentide keskmine pikkus suurem kui USA populatsiooni meeste keskmine pikkus (178.3 cm mediaan)?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(a1<span class="op">$</span>Value<span class="op">&gt;</span><span class="fl">178.3</span>)<span class="op">/</span><span class="dv">4000</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mode</span>(a1<span class="op">$</span>Value)</code></pre></div>
<pre><code>## [1] 184.5883</code></pre>
<p>Ligikaudu 100% tõenäosusega (valimis on 1 mees alla 182 cm, ja tema on 177 cm). Lühikesed jupatsid ei saa Ameerikamaal presidendiks!</p>
<p>Edaspidi kasutame bootstrappimiseks veidi moodsamat meetodit — Bayesian bootstrap — mis töötab veidi paremini väikeste valimite korral. Aga üldiselt on tulemused sarnased.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bayesboot)
<span class="co"># Heights of the last ten American presidents in cm (Kennedy to Obama).</span>
heights &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">183</span>, <span class="dv">192</span>, <span class="dv">182</span>, <span class="dv">183</span>, <span class="dv">177</span>, <span class="dv">185</span>, <span class="dv">188</span>, <span class="dv">188</span>, <span class="dv">182</span>, <span class="dv">185</span>);
b1 &lt;-<span class="st"> </span><span class="kw">bayesboot</span>(heights, mean)
<span class="kw">plot</span>(b1)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-198-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#summary(b1)</span>
<span class="co">#hist(b1)</span>
<span class="kw">HPDI</span>(b1<span class="op">$</span>V1, <span class="dt">prob=</span><span class="fl">0.95</span>)</code></pre></div>
<pre><code>##    |0.95    0.95| 
## 182.1153 186.8777</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># it&#39;s more efficient to use the a weighted statistic (but you can use a normal statistic like mean() or median() as well - as above).</span>
b2 &lt;-<span class="st"> </span><span class="kw">bayesboot</span>(heights, weighted.mean, <span class="dt">use.weights =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>It can also be easily post processed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the probability that the mean is &gt; 182 cm.</span>
<span class="kw">mean</span>( b1[,<span class="dv">1</span>] <span class="op">&gt;</span><span class="st"> </span><span class="dv">182</span>)</code></pre></div>
<pre><code>## [1] 0.98075</code></pre>
<p>2 keskväärtuse erinevus (keskmine1 - keskmine2):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">a=</span><span class="kw">rnorm</span>(<span class="dv">10</span>), <span class="dt">b=</span><span class="kw">rnorm</span>(<span class="dv">10</span>,<span class="dv">1</span>,<span class="dv">1</span>))
m1 &lt;-<span class="st"> </span><span class="kw">bayesboot</span>(df<span class="op">$</span>a, mean)
m2 &lt;-<span class="st"> </span><span class="kw">bayesboot</span>(df<span class="op">$</span>b, mean)
m12 &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(m1, m2) 
m12 &lt;-<span class="st"> </span>m12 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">value=</span>m12[,<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>m12[,<span class="dv">1</span>])
<span class="kw">hist</span>(m12<span class="op">$</span>value)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-201-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">median</span>(m12<span class="op">$</span>value)</code></pre></div>
<pre><code>## [1] 1.624235</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mode</span>(m12<span class="op">$</span>value)</code></pre></div>
<pre><code>## [1] 1.543269</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">HPDI</span>(m12<span class="op">$</span>value)</code></pre></div>
<pre><code>##    |0.89    0.89| 
## 1.116852 2.183880</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#library(BayesianFirstAid); bayes.t.test(m1, m2) </span>
<span class="co">#will give a similar, but fully Bayesian, result</span>
<span class="co">#requires JAGS.</span></code></pre></div>
<p><strong>Bayesian bootstrap SD arvutamiseks.</strong></p>
<p>When use.weights = FALSE it is important that the summary statistics does not change as a function of sample size. This is the case with the sample standard deviation, so here we have to implement a function calculating the population standard deviation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pop.sd &lt;-<span class="st"> </span><span class="cf">function</span>(x) {
  n &lt;-<span class="st"> </span><span class="kw">length</span>(x)
  <span class="kw">sd</span>(x) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>( (n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>n)
}

b3 &lt;-<span class="st"> </span><span class="kw">bayesboot</span>(heights, pop.sd)
<span class="kw">summary</span>(b3)</code></pre></div>
<pre><code>## Bayesian bootstrap
## 
## Number of posterior draws: 4000 
## 
## Summary of the posterior (with 95% Highest Density Intervals):
##  statistic     mean        sd  hdi.low hdi.high
##         V1 3.663116 0.7391744 2.230017 5.031605
## 
## Quantiles:
##  statistic    q2.5%     q25%   median     q75%   q97.5%
##         V1 2.323455 3.121658 3.654356 4.159498 5.158932
## 
## Call:
##  bayesboot(data = heights, statistic = pop.sd)</code></pre>
<p>A Bayesian bootstrap analysis of a correlation coefficient</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Data comparing two methods of measuring blood flow.</span>
blood.flow &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">dye =</span> <span class="kw">c</span>(<span class="fl">1.15</span>, <span class="fl">1.7</span>, <span class="fl">1.42</span>, <span class="fl">1.38</span>, <span class="fl">2.80</span>, <span class="fl">4.7</span>, <span class="fl">4.8</span>, <span class="fl">1.41</span>, <span class="fl">3.9</span>),
  <span class="dt">efp =</span> <span class="kw">c</span>(<span class="fl">1.38</span>, <span class="fl">1.72</span>, <span class="fl">1.59</span>, <span class="fl">1.47</span>, <span class="fl">1.66</span>, <span class="fl">3.45</span>, <span class="fl">3.87</span>, <span class="fl">1.31</span>, <span class="fl">3.75</span>))

<span class="co"># Using the weighted correlation (corr) from the boot package.</span>
<span class="kw">library</span>(boot)
b4 &lt;-<span class="st"> </span><span class="kw">bayesboot</span>(blood.flow, corr, <span class="dt">R =</span> <span class="dv">1000</span>, <span class="dt">use.weights =</span> <span class="ot">TRUE</span>)
<span class="kw">plot</span>(b4)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-203-1.png" width="672" /></p>
<p>A Bayesian bootstrap analysis of lm coefficients</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># A custom function that returns the coefficients of</span>
<span class="co"># a weighted linear regression on the blood.flow data</span>
lm.coefs &lt;-<span class="st"> </span><span class="cf">function</span>(d, w) {
  <span class="kw">coef</span>( <span class="kw">lm</span>(efp <span class="op">~</span><span class="st"> </span>dye, <span class="dt">data =</span> d, <span class="dt">weights =</span> w) )
}

b5 &lt;-<span class="st"> </span><span class="kw">bayesboot</span>(blood.flow, lm.coefs, <span class="dt">R =</span> <span class="dv">1000</span>, <span class="dt">use.weights =</span> <span class="ot">TRUE</span>)
<span class="kw">plot</span>(b5)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-204-1.png" width="672" /></p>
<p>Bootstrappimine on väga hea meetod, mis sõltub väiksemast arvust eeldustest kui statistikas tavaks. Bootstrap ei eelda, et andmed on normaaljaotusega või mõne muu matemaatiliselt lihtsa jaotusega. Tema põhiline eeldus on, et valim peegeldab populatsiooni — mis ei pruugi kehtida väikeste valimite korral ja kallutatud (mitte-juhuslike) valimite korral.</p>
<p>Bootstrappimisel on üks konseptuaalne puudus, mis on eriti tõsine väikeste valimite korral. Võtame oma näite USA presidentidest. Meie valimi liikmed on kõik presideerinud viimase 50 aasta jooksul, aga selle aja jooksul on inimeste keskmine pikkus jõudsalt kasvanud. Kui me tahame ennustada järgmise 50 aasta keskmist presidentide pikkust, peaksime selle faktiga arvestama. Aga bootstrap ei jäta meile sellist võimalust. Vähemalt mitte lihtsat.</p>
<p>Siin tuleb appi Bayesi statistika oma täies hiilguses. Selles paradigmas ei arvesta me mitte ainult andmetega vaid ka taustateadmistega, sünteesides need kokku üheks posterioorseks jaotuseks ehk järeljaotuseks. Selle jaotuse arvutamine erineb bootstrapist, kuid tema tõlgendus ja praktiline töö sellega on samasugune. Erinevalt bootstrapist on Bayes parameetriline meetod, mis sõltub andmete modelleerimisest modeleerija poolt ette antud jaotustesse (normaaljaotus, t jaotus jne). Tegelikult peame me Bayesi arvutuseks modelleerima vähemalt kaks erinevat jaotust: andmete jaotus, mida me kutsume likelihoodiks ehk tõepäraks, ning eelneva teadmise mudel ehk prior, mida samuti modeleeritakse tõenäosusjaotusena.</p>
</div>
<div id="bayesi-pohimote" class="section level2">
<h2><span class="header-section-number">11.1</span> 3.2. Bayesi põhimõte</h2>
<p>Bayesi arvutuseks on meil vaja teada</p>
<ol style="list-style-type: decimal">
<li><p>milline on “<em>parameter space</em>” ehk parameetriruum? Parameetriruum koosneb kõikidest loogiliselt võimalikest parameetriväärtustest. Näiteks kui me viskame ühe korra münti, koosneb parameetriruum kahest elemendist: 0 ja 1, ehk null kulli ja üks kull. See ammendab võimalike sündmuste nimekirja. Kui me aga hindame mõnd pidevat suurust (keskmine pikkus, tõenäosus 0 ja 1 vahel jms), koosneb parameetriruum lõpmata paljudest elementidest (arvudest).</p></li>
<li><p>milline on “<em>likelihood function</em>” ehk tõepärafunktsioon? Me omistame igale parameetriruumi elemendile (igale võimalikule parameetri väärtusele) tõepära. Tõepära parameetri väärtusel x on defineeritud kui tõenäosus, millega me võiksime kohata oma andmeid, juhul kui x oleks päriselt õige parameetri väärtus. Teisisõnu, tõepära on kooskõla määr andmete ja parameetri väärtuse x vahel. Tõepära = Pr(andmed I parameetri väärtus). Näiteks, kui tõenäolised on meie andmed, kui USA keskmine president on juhtumisi 183.83629 cm pikkune? Sageli on tõepära modelleeritud pideva tõenäosusfunktsioonina (näiteks normaaljaotusena), mis täielikult katab pideva väärtusruumi. Tõepärafunktsioon ei summeeru 100-le protsendile — see on normaliseerimata.</p></li>
<li><p>milline on “<em>prior function</em>” ehk prior? Kui tõepära on modelleeritud pideva funktsioonina siis on ka prior modelleeritud pideva tõenäosusjaotusena (aga ta ei pea olema samas jaotusmudelis, kus tõepära). Erinevus seisneb selles, et kui tõepärafunktsioon annab meie andmete tõenäosuse igal parameetriväärtusel, siis prior annab iga parameetriväärtuse tõenäosuse olukorras, kus me üldse ei arvesta oma andmete olemasoluga. Me omistame igale parameetriruumi väärtusele eelneva tõenäosuse, et see väärtus on üks ja ainus tõene väärtus. Prior jaotus summeerub 1-le. Prior kajastab meie konkreetsetest andmetest sõltumatut arvamust, kui suure tõenäosusega on just see parameetri väärtus tõene; seega seda, mida me usume enne oma andmete nägemist. Nendel parameetri väärtustel, kus prior (või tõepära) = 0%, on ka posteerior garanteeritult 0%. See tähendab, et kui te olete 100% kindel, et mingi sündmus on võimatu, siis ei suuda ka mäekõrgune hunnik uusi andmeid teie uskumust muuta (eelduselt, et te olete ratsionaalne inimene).</p></li>
</ol>
<p><a href="http://optics.eee.nottingham.ac.uk/match/uncertainty.php" class="uri">http://optics.eee.nottingham.ac.uk/match/uncertainty.php</a> aitab praktikas priorit modelleerida (proovige <em>Roulette</em> meetodit).</p>
<p>Kui te eelnevast päriselt aru ei saanud, ärge muretsege. Varsti tulevad puust ja punaseks näited likelihoodi ja priori kohta.</p>
<p>Edasi on lihtne. Arvuti võtab tõepärafunktsiooni ja priori, korrutab need üksteisega läbi ning seejärel normaliseerib saadud jaotuse nii, et jaotusealune pindala võrdub ühega. Saadud tõenäosusjaotus ongi posteeriorne jaotus ehk posteerior ehk järeljaotus. Kogu lugu.</p>
<p>Me teame juba palju aastakümneid, et Bayesi teoreem on sellisele ülesandele parim võimalik lahendus. Lihtsamad ülesanded lahendame me selle abil täiuslikult. Kuna parameetrite arvu kasvuga mudelis muutub Bayesi teoreemi läbiarvutamine eksponentsiaalselt arvutusmahukamaks (sest läbi tuleb arvutada kõikide parameetrite väärtuste kõikvõimalikud kombinatsioonid), oleme sunnitud vähegi keerulisemad ülesanded lahendama umbkaudu, asendades Bayesi teoreemi <em>ad hoc</em> MCMC algoritmidega, mis teie arvutis peituva propelleri Karlsoni kombel lendu saadavad selleks, et “otse” sämplida arve posterioorsest jaotusest. Meie kasutatava MCMC <em>Hamiltonian Monte Carlo</em> mootori nimi on Stan. See on R-st eraldiseisev programm, millel on aga R-i interface R-i pakettide rstan(), rethinking(), rstanarm() jt kaudu. Meie töötame ka edaspidi puhtalt R-s, mis automaatselt suunab meie mudelid ja muud andmed Stani, kus need läbi arvutatakse ja seejärel tulemused R-i tagasi saadetakse. Tulemuste töötlus ja graafiline esitus toimub meie poolt jällegi R-is. Seega ei pea me ise kordagi Stani avama. (Stanil on sarnased interfaced ka Pythoni, Matlabi jt keeltega.)</p>
<p>Alustame siiski lihtsa näitega, mida saab käsitsi läbi arvutada.</p>
<div id="naide" class="section level3">
<h3><span class="header-section-number">11.1.1</span> 1. näide</h3>
<p>Me teame, et suremus haigusesse on 50% ja meil on palatis 3 patsienti, kes seda haigust põevad. Seega on meil kaks andmetükki (50% ja n=3). Küsimus: mitu meie patsienti oodatavalt hinge heidavad? Eeldusel, et meie patsiendid on iseseisvad (näiteks ei ole sugulased), on meil tüüpiline mündiviske olukord.</p>
<p>Parameetriruum: 0 elus, 1 elus, 2 elus ja 3 elus. Seega on meil neljaliikmeline parameetriruumi.</p>
<p>Edasi loeme üles kõik võimalikud sündmusteahelad, mis saavad loogiliselt juhtuda (et saada tõepärafunktsioon).</p>
<p>Me heidame münti 3 korda: H - kiri, T - kull</p>
<p>Võimalikud sündmused on:</p>
<p>HHH, HTH, THH, HHT, HTT, TTH, THT, TTT,</p>
<p>Kui Pr(H) = 0.5 ning H = elus ja T = surnud, siis lugedes kokku kõik võimalikud sündmused:</p>
<ul>
<li>0 elus - 1,</li>
<li>1 elus - 3,</li>
<li>2 elus - 3,</li>
<li>3 elus - 1</li>
</ul>
<p>Nüüd teame parameetriruumi igale liikme kohta, kui suure tõenäosusega me ootame selle realiseerumist. Näiteks, Pr(0 elus) = 1/8, Pr(1 elus) = 3/8, Pr(1 või 2 elus) = 6/8 jne</p>
<p>Selle teadmise saab konverteerida tõepärafunktsiooniks</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x&lt;-<span class="kw">seq</span>(<span class="dt">from=</span> <span class="dv">0</span>, <span class="dt">to=</span><span class="dv">3</span>) <span class="co">#parameter space as a grid</span>
y&lt;-<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">1</span>) <span class="co">#likelihood - </span>
<span class="kw">plot</span>(x,y, <span class="dt">ylab=</span><span class="st">&quot;number of possibilities&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;number of deaths&quot;</span>, <span class="dt">type=</span><span class="st">&quot;b&quot;</span>, <span class="dt">main=</span><span class="st">&quot;likelihood&quot;</span>)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-205-1.png" width="672" /></p>
<p>Siit näeme, et üks surm ja kaks surma on sama tõenäolised ja üks surm on kolm korda tõenäolisem kui null surma (või kolm surma).</p>
<p>Tõepära annab meile tõenäosuse Pr(mortality=0.5 &amp; N=3) igale loogiliselt võimalikule surmade arvule (0 kuni 3).</p>
<p>Me saame sama tulemuse kasutades binoomjaotuse mudelit (sest mitteformaalselt kasutasime ka ennist sama mudelit).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x&lt;-<span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">3</span>)
y &lt;-<span class="st"> </span><span class="kw">dbinom</span>(x,<span class="dv">3</span>, <span class="fl">0.5</span>)
<span class="kw">plot</span>(x, y, <span class="dt">type=</span><span class="st">&quot;b&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;nr of deaths&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability of x deaths&quot;</span>, <span class="dt">main=</span><span class="st">&quot;probability of x deaths out of 3 patients if Pr(Heads)=0.5&quot;</span>)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-206-1.png" width="672" /></p>
<p>Nüüd proovime seda koodi olukorras, kus meil on 9 patsienti ja suremus on 0.67</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x&lt;-<span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">9</span>)
y &lt;-<span class="st"> </span><span class="kw">dbinom</span>(x,<span class="dv">9</span>, <span class="fl">0.67</span>)
<span class="kw">plot</span>(x, y, <span class="dt">type=</span><span class="st">&quot;b&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;nr of deaths&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probability of x deaths&quot;</span>, <span class="dt">main=</span><span class="st">&quot;probability of x out of 9 deaths if Pr(Heads)=0.67&quot;</span>)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-207-1.png" width="672" /></p>
<p>Lisame siia tasase priori (lihtsuse huvides) ja arvutame posterioorse jaotuse kasutades Bayesi teoreemi. Igale parameetri väärtusele, tõepära * prior on proportsionaalne posterioorse tõenäosusega, et just see parameetri väärtus on see ainus tõene väärtus. Posterioorsed tõenäosused normaliseeritakse nii, et nad summeeruksid 1-le.</p>
<p>Me defineerime X telje kui rea 10-st arvust (0 kuni 9 surma) ja arvutame tõepära igale neist 10-st arvust. Sellega ammendame me kõik loogiliselt võimalikud parameetri väärtused.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define grid</span>
p_grid &lt;-<span class="st"> </span><span class="kw">seq</span>( <span class="dt">from=</span><span class="dv">0</span> , <span class="dt">to=</span><span class="dv">9</span> )
<span class="co"># define flat prior</span>
prior &lt;-<span class="st"> </span><span class="kw">rep</span>( <span class="dv">1</span> , <span class="dv">10</span> )
<span class="co"># compute likelihood at each value in grid</span>
likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>( p_grid , <span class="dt">size=</span><span class="dv">9</span> , <span class="dt">prob=</span><span class="fl">0.67</span> )

<span class="co"># compute product of likelihood and prior</span>
unstd.posterior &lt;-<span class="st"> </span>likelihood <span class="op">*</span><span class="st"> </span>prior 

<span class="co"># normalize the posterior, so that it sums to 1</span>
posterior &lt;-<span class="st"> </span>unstd.posterior<span class="op">/</span><span class="kw">sum</span>(unstd.posterior)
<span class="co"># sum(posterior) == 1 </span>

<span class="kw">plot</span>( <span class="dt">x =</span> p_grid , <span class="dt">y =</span> posterior , <span class="dt">type=</span><span class="st">&quot;b&quot;</span> ,
    <span class="dt">xlab=</span><span class="st">&quot;nr of deaths&quot;</span> , <span class="dt">ylab=</span><span class="st">&quot;posterior probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;posterior distribution&quot;</span> )</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-208-1.png" width="672" /></p>
<p>See on parim võimalik teadmine, mitu kirstu tasuks tellida, arvestades meie priori ja likelihoodi mudelitega. Näiteks, sedapalju, kui surmad ei ole üksteisest sõltumatud, on meie tõepäramudel (binoomjaotus) vale.</p>
</div>
<div id="naide-sonastame-oma-probleemi-umber" class="section level3">
<h3><span class="header-section-number">11.1.2</span> 2. näide: sõnastame oma probleemi ümber</h3>
<p>Mis siis, kui me ei tea suremust ja tahaksime seda välja arvutada? Kõik, mida me teame on, et 6 patsienti 9st surid. Nüüd koosnevad andmed 9 patsiendi morbiidsusinfost (parameeter, mille väärtust me eelmises näites arvutasime) ja parameeter, mille väärtust me ei tea, on surmade üldine sagedus (see parameeter oli eelmises näites fikseeritud, ja seega kuulus andmete hulka).</p>
<p>Seega on meil 1) parameetriruum 0% kuni 100% suremus (0st 1-ni), mis sisaldab lõpmata palju numbreid.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>kaks võimalikku sündmust (surnud, elus), seega binoomjaotusega modelleeritud tõepärafunktsioon. Nagu me juba teame, on r funkrsioonis dbinom() kolm argumenti: surmade arv, patsientide koguarv ja surmade tõenäosus. Seekord oleme me fikseerinud esimesed kaks ja soovime arvutada kolmanda.</p></li>
<li><p>tasane prior, mis ulatub 0 ja 1 vahel. Me valisime selle priori selleks, et mitte muuta tõepärafunktsiooni kuju. See ei tähenda, et me arvaksime, et tasane prior on mitteinformatiivne. Tasane prior tähendab, et me usume, et suremuse kõik väärtused 0 ja 1 vahel on võrdselt tõenäolised. See on vägagi informatsioonirohke (ebatavaline) viis maailma näha ükskõik mis haiguse puhul!</p></li>
</ol>
<p><strong>Tõepära parameetri väärtusel x on tõenäosus kohata meie andmeid, kui x on juhtumisi parameetri tegelik väärtus.</strong> Meie näites koosneb tõepärafunktsioon tõenäosustest, et kuus üheksast patsiendist surid igal võimalikul suremuse väärtusel (0…1). Kuna see on lõpmatu rida, teeme natuke sohki ja arvutame tõepära 20-l valitud suremuse väärtusel</p>
<pre><code>Tehniliselt on sinu andmete tõepärafunktsioon agregeeritud iga üksiku andmepunkti tõepärafunktsioonist. 
Seega vaatab Bayes igat andmepunkti eraldi (andmete sisestamise järjekord ei loe).</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define grid (mortality at 20 evenly spaced probabilities from 0 to 1)</span>
p_grid &lt;-<span class="st"> </span><span class="kw">seq</span>( <span class="dt">from=</span><span class="dv">0</span> , <span class="dt">to=</span><span class="dv">1</span> , <span class="dt">length.out=</span><span class="dv">20</span> )
<span class="co"># define prior</span>
prior &lt;-<span class="st"> </span><span class="kw">rep</span>( <span class="dv">1</span> , <span class="dv">20</span> )
<span class="co"># compute likelihood at each value in grid</span>
likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>( <span class="dv">6</span> , <span class="dt">size=</span><span class="dv">9</span> , <span class="dt">prob=</span>p_grid )
<span class="co"># compute product of likelihood and prior</span>

<span class="kw">plot</span>(p_grid, prior, <span class="dt">type=</span><span class="st">&quot;b&quot;</span>, <span class="dt">main=</span><span class="st">&quot;prior&quot;</span>)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-209-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p_grid &lt;-<span class="st"> </span><span class="kw">seq</span>( <span class="dt">from=</span><span class="dv">0</span> , <span class="dt">to=</span><span class="dv">1</span> , <span class="dt">length.out=</span><span class="dv">20</span> )
likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>( <span class="dv">6</span> , <span class="dt">size=</span><span class="dv">9</span> , <span class="dt">prob=</span>p_grid )
<span class="kw">plot</span>(p_grid, likelihood, <span class="dt">type=</span><span class="st">&quot;b&quot;</span>, <span class="dt">main=</span><span class="st">&quot;the likelihood function&quot;</span>)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-209-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">unstd.posterior &lt;-<span class="st"> </span>likelihood <span class="op">*</span><span class="st"> </span>prior
<span class="co"># standardize the posterior, so that it sums to 1</span>
posterior &lt;-<span class="st"> </span>unstd.posterior <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(unstd.posterior)

<span class="kw">plot</span>( <span class="dt">x =</span> p_grid , <span class="dt">y =</span> posterior , <span class="dt">type=</span><span class="st">&quot;b&quot;</span> ,
    <span class="dt">xlab=</span><span class="st">&quot;mortality&quot;</span> , <span class="dt">ylab=</span><span class="st">&quot;posterior probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;posterior distribution&quot;</span> )</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-209-3.png" width="672" /></p>
<p>Nüüd on meil posterioorne tõenäosusfunktsioon, mis summeerub 1-le ja mis sisaldab kogu meie teadmist suremuse kohta.</p>
<div id="kui-n1" class="section level4">
<h4><span class="header-section-number">11.1.2.1</span> Kui n=1</h4>
<p>Bayes on lahe sest tema hinnangud väiksele N-le on loogiliselt sama pädevad kui suurele N-le. See ei ole nii klassikalises sageduslikus statistikas, kus paljud testid on välja töötatud N = Inf eeldusel ja töötavad halvasti väikeste valimitega.</p>
<p>Hea küll, me arvutame jälle suremust.</p>
<p>Bayes töötab andmepunkti kaupa (see et me talle ennist kõik andmed korraga ette andsime, on puhtalt meie mugavus)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define grid</span>
p_grid &lt;-<span class="st"> </span><span class="kw">seq</span>( <span class="dt">from=</span><span class="dv">0</span> , <span class="dt">to=</span><span class="dv">1</span> , <span class="dt">length.out=</span><span class="dv">20</span> )
<span class="co"># define prior</span>
prior &lt;-<span class="st"> </span><span class="kw">rep</span>( <span class="dv">1</span> , <span class="dv">20</span> )
<span class="co"># compute likelihood at each value in grid</span>
likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>( <span class="dv">1</span> , <span class="dt">size=</span><span class="dv">1</span> , <span class="dt">prob=</span>p_grid )
<span class="co"># compute product of likelihood and prior</span>
unstd.posterior &lt;-<span class="st"> </span>likelihood <span class="op">*</span><span class="st"> </span>prior
<span class="co"># standardize the posterior, so that it sums to 1</span>
posterior &lt;-<span class="st"> </span>unstd.posterior <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(unstd.posterior)

<span class="kw">plot</span>( <span class="dt">x =</span> p_grid , <span class="dt">y =</span> posterior , <span class="dt">type=</span><span class="st">&quot;b&quot;</span> ,
    <span class="dt">xlab=</span><span class="st">&quot;mortality&quot;</span> , <span class="dt">ylab=</span><span class="st">&quot;posterior probability&quot;</span> )</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-210-1.png" width="672" /></p>
<p>esimene patsient suri - 0 mortaalsus ei ole enam loogiliselt võimalik (välja arvatud siis kui prior selle koha peal = 0) ja mortaalsus 100% on andmetega (tegelikult andmega) parimini kooskõlas. Posteerior on nulli ja 100% vahel sirge sest vähene sissepandud informatsioon lihtsalt ei võimalda enamat.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define grid</span>
p_grid &lt;-<span class="st"> </span><span class="kw">seq</span>( <span class="dt">from=</span><span class="dv">0</span> , <span class="dt">to=</span><span class="dv">1</span> , <span class="dt">length.out=</span><span class="dv">20</span> )
<span class="co"># define prior</span>
prior &lt;-<span class="st"> </span>posterior
<span class="co"># compute likelihood at each value in grid</span>
likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>( <span class="dv">1</span> , <span class="dt">size=</span><span class="dv">1</span> , <span class="dt">prob=</span>p_grid )
<span class="co"># compute product of likelihood and prior</span>
unstd.posterior &lt;-<span class="st"> </span>likelihood <span class="op">*</span><span class="st"> </span>prior
<span class="co"># standardize the posterior, so that it sums to 1</span>
posterior1 &lt;-<span class="st"> </span>unstd.posterior <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(unstd.posterior)

<span class="kw">plot</span>( <span class="dt">x =</span> p_grid , <span class="dt">y =</span> posterior1 , <span class="dt">type=</span><span class="st">&quot;b&quot;</span> ,
    <span class="dt">xlab=</span><span class="st">&quot;mortality&quot;</span> , <span class="dt">ylab=</span><span class="st">&quot;posterior probability&quot;</span> )</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-211-1.png" width="672" /></p>
<p>Teine patsient suri. Nüüd ei ole 0 ja 1 vahel enam sirge posteerior. Posteerior on kaldu 100 protsendi poole, mis on ikka kõige tõenäolisem väärtus.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define grid</span>
p_grid &lt;-<span class="st"> </span><span class="kw">seq</span>( <span class="dt">from=</span><span class="dv">0</span> , <span class="dt">to=</span><span class="dv">1</span> , <span class="dt">length.out=</span><span class="dv">20</span> )
<span class="co"># define prior</span>
prior &lt;-<span class="st"> </span>posterior1
<span class="co"># compute likelihood at each value in grid</span>
likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>( <span class="dv">0</span> , <span class="dt">size=</span><span class="dv">1</span> , <span class="dt">prob=</span>p_grid )
<span class="co"># compute product of likelihood and prior</span>
unstd.posterior &lt;-<span class="st"> </span>likelihood <span class="op">*</span><span class="st"> </span>prior
<span class="co"># standardize the posterior, so that it sums to 1</span>
posterior2 &lt;-<span class="st"> </span>unstd.posterior <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(unstd.posterior)

<span class="kw">plot</span>( <span class="dt">x =</span> p_grid , <span class="dt">y =</span> posterior2 , <span class="dt">type=</span><span class="st">&quot;b&quot;</span> ,
    <span class="dt">xlab=</span><span class="st">&quot;mortality&quot;</span> , <span class="dt">ylab=</span><span class="st">&quot;posterior probability&quot;</span> )</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-212-1.png" width="672" /></p>
<p>Kolmas patsient jäi ellu - 0 ja 100% mortaalsus on seega võimaluste nimekirjast maas ning suremus on ikka kaldu valimi keskmise poole (75%).</p>
<p>Teeme sedasama prioriga, mis ei ole tasane. See illustreerib tõsiasja, et kui N on väike siis domineerib prior posteerior jaotust. (Suure N korral on vastupidi, priori kuju on sageli vähetähtis.)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define grid</span>
p_grid &lt;-<span class="st"> </span><span class="kw">seq</span>( <span class="dt">from=</span><span class="dv">0</span> , <span class="dt">to=</span><span class="dv">1</span> , <span class="dt">length.out=</span><span class="dv">20</span> )
<span class="co"># define prior</span>
prior &lt;-<span class="st"> </span><span class="kw">c</span>( <span class="kw">seq</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>), <span class="kw">seq</span>(<span class="dt">from=</span> <span class="dv">10</span>, <span class="dt">to=</span> <span class="dv">1</span>) )
<span class="co"># compute likelihood at each value in grid</span>
likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>( <span class="dv">1</span> , <span class="dt">size=</span><span class="dv">1</span> , <span class="dt">prob=</span>p_grid )
<span class="co"># compute product of likelihood and prior</span>
unstd.posterior &lt;-<span class="st"> </span>likelihood <span class="op">*</span><span class="st"> </span>prior
<span class="co"># standardize the posterior, so that it sums to 1</span>
posterior &lt;-<span class="st"> </span>unstd.posterior <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(unstd.posterior)

<span class="kw">plot</span>(<span class="dt">x=</span><span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">y=</span>prior, <span class="dt">type=</span><span class="st">&quot;b&quot;</span>, <span class="dt">main=</span><span class="st">&quot;prior&quot;</span>)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-213-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>( <span class="dt">x =</span> p_grid , <span class="dt">y =</span> posterior , <span class="dt">type=</span><span class="st">&quot;b&quot;</span> ,
    <span class="dt">xlab=</span><span class="st">&quot;mortality&quot;</span> , <span class="dt">ylab=</span><span class="st">&quot;posterior probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;posterior&quot;</span>)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-213-2.png" width="672" /> 1. patsient suri</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define grid</span>
p_grid &lt;-<span class="st"> </span><span class="kw">seq</span>( <span class="dt">from=</span><span class="dv">0</span> , <span class="dt">to=</span><span class="dv">1</span> , <span class="dt">length.out=</span><span class="dv">20</span> )
<span class="co"># define prior</span>
prior &lt;-<span class="st"> </span>posterior
<span class="co"># compute likelihood at each value in grid</span>
likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>( <span class="dv">1</span> , <span class="dt">size=</span><span class="dv">1</span> , <span class="dt">prob=</span>p_grid )
<span class="co"># compute product of likelihood and prior</span>
unstd.posterior &lt;-<span class="st"> </span>likelihood <span class="op">*</span><span class="st"> </span>prior
<span class="co"># standardize the posterior, so it sums to 1</span>
posterior1 &lt;-<span class="st"> </span>unstd.posterior <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(unstd.posterior)

<span class="kw">plot</span>(<span class="dt">x=</span><span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">y=</span>prior, <span class="dt">type=</span><span class="st">&quot;b&quot;</span>, <span class="dt">main=</span><span class="st">&quot;prior&quot;</span>)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-214-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>( p_grid , posterior1 , <span class="dt">type=</span><span class="st">&quot;b&quot;</span> ,
    <span class="dt">xlab=</span><span class="st">&quot;mortality&quot;</span> , <span class="dt">ylab=</span><span class="st">&quot;posterior probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;posterior&quot;</span> )</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-214-2.png" width="672" /></p>
<p>Teine patsient suri</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># define grid</span>
p_grid &lt;-<span class="st"> </span><span class="kw">seq</span>( <span class="dt">from=</span><span class="dv">0</span> , <span class="dt">to=</span><span class="dv">1</span> , <span class="dt">length.out=</span><span class="dv">20</span> )
<span class="co"># define prior</span>
prior &lt;-<span class="st"> </span>posterior1
<span class="co"># compute likelihood at each value in grid</span>
likelihood &lt;-<span class="st"> </span><span class="kw">dbinom</span>( <span class="dv">0</span> , <span class="dt">size=</span><span class="dv">1</span> , <span class="dt">prob=</span>p_grid )
<span class="co"># compute product of likelihood and prior</span>
unstd.posterior &lt;-<span class="st"> </span>likelihood <span class="op">*</span><span class="st"> </span>prior
<span class="co"># standardize the posterior, so that it sums to 1</span>
posterior2 &lt;-<span class="st"> </span>unstd.posterior <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(unstd.posterior)
<span class="kw">plot</span>(<span class="dt">x=</span><span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dt">y=</span>prior, <span class="dt">type=</span><span class="st">&quot;b&quot;</span>, <span class="dt">main=</span><span class="st">&quot;prior&quot;</span>)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-215-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>( <span class="dt">x =</span> p_grid , <span class="dt">y =</span> posterior2 , <span class="dt">type=</span><span class="st">&quot;b&quot;</span> ,
    <span class="dt">xlab=</span><span class="st">&quot;mortality&quot;</span> , <span class="dt">ylab=</span><span class="st">&quot;posterior probability&quot;</span>, <span class="dt">main=</span><span class="st">&quot;posterior&quot;</span>  )</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-215-2.png" width="672" /> 3. patsient jäi ellu. Nüüd on posteeriori tipp mitte 75% juures nagu ennist, vaid kuskil 50% juures — tänu priorile.</p>
</div>
</div>
</div>
<div id="mudelite-keel" class="section level2">
<h2><span class="header-section-number">11.2</span> 2.3. Mudelite keel</h2>
<p>Siin vaatame kuidas kirjeldada mudelit nii, et masin selle ära tunneb. Meie mudelid töötavad läbi rethinking() paketi. See raamatukogu pakub kaks võimalust, kuidas mudelit arvutada, mis mõlemad kasutavad sama notatsiooni. Mõlemad võimalused arvutavad posteeriori mitte Bayesi teoreemi kasutades (nagu me ennist tegime), vaid kasutades stohhastilisi meetodeid, mis iseloomustavad posteeriori umbkaudu (aga piisavalt täpselt). Põhjuseks on, et keerulisemate mudelite korral on Bayesi teoreemi kasutamine liialt arvutusmahukas.</p>
<p>Esiteks rethinking::map() leiab posteeriori tipu ja selle lähedal funktsiooni tõusunurga. Siin on eelduseks, et posteerior on normaaljaotus. See eeldus kehtib alati, kui nii prior kui tõepära on modelleeritud normaaljaotusena (ja ka paljudel muudel juhtudel).</p>
<p>Teine võimalus on rethinking::map2stan(), mis suunab teie kirjutatud mudeli Stan-i. Stan teeb <em>Hamilonian Monte Carlo</em> simulatsiooni, kasutades valget maagiat selleks, et tõmmata valim otse posteerioorsest jaotusest. See on väga moodne lähenemine statistikale, töötab oluliselt aeglasemalt kui map, aga ei sõltu normaaljaotustest ning suudab arvutada hierarhilisi mudeleid, mis map-le üle jõu käivad.</p>
<p>Me võime sama mudeli kirjelduse sõõta mõlemasse funktsiooni.</p>
<p>Lihtne mudel näeb välja niimodi:</p>
<p>dead ~ dbinom(9, p) , # binomial likelihood</p>
<p>p ~ dunif(0, 1) # uniform prior</p>
<p>Tõepärafunktsioon on modeleeritud binoomjaotusena. Parameeter, mille väärtust määratakse on p, ehk suremus. See on ainus parameeter, mille väärtust me siin krutime. NB! igale parameetrile peab vastama oma prior. Meil on selles mudelis täpselt 1 parameeter ja 1 prior. Vastuseks saame selle ainsa parameetri posterioorse jaotuse. Hiljem näeme, et kui meil on näiteks 452 parameetrit, mille väärtusi me koos arvutame, siis on meil ka 452 priorit ja 452 posterioorset jaotust.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
m1 &lt;-<span class="st"> </span><span class="kw">map</span>(
    <span class="kw">alist</span>(
        dead <span class="op">~</span><span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">9</span>, p) ,  <span class="co"># binomial likelihood</span>
        p <span class="op">~</span><span class="st"> </span><span class="kw">dunif</span>(<span class="dv">0</span>, <span class="dv">1</span>)     <span class="co"># uniform prior</span>
), <span class="dt">data=</span><span class="kw">list</span>(<span class="dt">dead=</span><span class="dv">6</span>) )

<span class="kw">precis</span>( m1 ) <span class="co"># summary of quadratic approximation</span></code></pre></div>
<pre><code>##   Mean StdDev 5.5% 94.5%
## p 0.67   0.16 0.42  0.92</code></pre>
<p>Nüüd tõmbame posteerioroorsest jaotusest valimi n=10 000. Selleks on funktsioon extract.samples()</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">samples&lt;-<span class="kw">extract.samples</span>(m1)
<span class="co">#hist(samples$p)</span>
<span class="kw">dens</span>(samples<span class="op">$</span>p)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-217-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#PI(samples$p, prob = 0.95) #leaves out equal 2.5% at both sides</span>
<span class="kw">HPDI</span>(samples<span class="op">$</span>p, <span class="dt">prob =</span> <span class="fl">0.95</span>) <span class="co">#highest density 95% at the center</span></code></pre></div>
<pre><code>##     |0.95     0.95| 
## 0.3592174 0.9678783</code></pre>
<p>Kuus patsienti üheksast surid ja nüüd me usume, et tegelik suremus võib olla nii madal kui 37% ja nii kõrge kui 97%. Kui me tahame paremat hinnangut on meil vaja kas rohkem patsiente või informatiivsemat priorit (paremat taustainfot).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
m2 &lt;-<span class="st"> </span><span class="kw">map</span>(
    <span class="kw">alist</span>(
        dead <span class="op">~</span><span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">90</span>,p) ,  <span class="co"># binomial likelihood</span>
        p <span class="op">~</span><span class="st"> </span><span class="kw">dunif</span>(<span class="dv">0</span>,<span class="dv">1</span>)     <span class="co"># uniform prior</span>
), <span class="dt">data=</span><span class="kw">list</span>(<span class="dt">dead=</span><span class="dv">60</span>) )
<span class="co"># display summary of quadratic approximation</span>
<span class="kw">precis</span>( m2 )</code></pre></div>
<pre><code>##   Mean StdDev 5.5% 94.5%
## p 0.67   0.05 0.59  0.75</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">samples&lt;-<span class="kw">extract.samples</span>(m2)
<span class="kw">dens</span>(samples<span class="op">$</span>p)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-219-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#PI(samples$p, prob = 0.95) #leaves out equal 2.5% at both sides</span>
<span class="kw">HPDI</span>(samples<span class="op">$</span>p, <span class="dt">prob =</span> <span class="fl">0.95</span>) <span class="co">#highest density 95% at the center</span></code></pre></div>
<pre><code>##     |0.95     0.95| 
## 0.5687602 0.7611587</code></pre>
<p>10 korda rohkem andmeid: nüüd on suremus määratud kuskile 57% ja 77% vahele (suure tõenäosusega)</p>
<div id="beta-prior" class="section level3">
<h3><span class="header-section-number">11.2.1</span> beta prior</h3>
<p>Nüüd anname sisse mõistlikuma struktuuriga priori: beta-jaotuse</p>
<p>Beta-prior katab vahemiku 0st 1ni ja sellel on 2 parameetrit, a ja b.</p>
<p>Siin mõned näited erinevatest beta parametriseeringutest</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length =</span> <span class="dv">1000</span>)
<span class="kw">plot</span>(x, <span class="kw">dbeta</span>(x, <span class="fl">0.2</span>, <span class="fl">0.2</span>))</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-220-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(x, <span class="kw">dbeta</span>(x, <span class="dv">1</span>, <span class="fl">0.2</span>))</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-220-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(x, <span class="kw">dbeta</span>(x, <span class="dv">1</span>, <span class="dv">1</span>))</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-220-3.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(x, <span class="kw">dbeta</span>(x, <span class="dv">2</span>, <span class="dv">1</span>))</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-220-4.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(x, <span class="kw">dbeta</span>(x, <span class="dv">4</span>, <span class="dv">1</span>))</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-220-5.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(x, <span class="kw">dbeta</span>(x, <span class="dv">2</span>, <span class="dv">2</span>))</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-220-6.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(x, <span class="kw">dbeta</span>(x, <span class="dv">4</span>, <span class="dv">4</span>))</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-220-7.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(x, <span class="kw">dbeta</span>(x, <span class="dv">200</span>, <span class="dv">100</span>))</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-220-8.png" width="672" /></p>
<p>beta(θ | a, b) jaotuse keskväärtus on</p>
<p><em>μ = a/(a + b)</em></p>
<p>ja mood on</p>
<p><em>ω = (a − 1)/(a + b − 2)</em> (juhul kui <em>a &gt; 1</em> ja <em>b &gt; 1</em>).</p>
<p>Seega, kui a=b, siis on keskmine ja mood 0.5. Kui a &gt; b, on keskmine ja mood &gt; 0.5 ja kuid a &lt; b, on mõlemad &lt; 0.5.</p>
<p>Beta jaotuse “laiuse” annab “konsentratsioon” <em>κ = a + b</em>. Mida suurem κ, seda kitsam jaotus.</p>
<p><em>a = μκ</em></p>
<p><em>b = (1 − μ)κ</em></p>
<p><em>a = ω(κ − 2) + 1</em></p>
<p><em>b = (1 − ω)(κ − 2) + 1</em> for <em>κ &gt; 2</em></p>
<p>Me võime κ-le omistada väärtuse nagu see oleks mündivisete arv, mis iseloomustab meie priori tugevust (juhul kui tõepära funktsioon tuleb andmetest, mis koosnevad selle sama mündi visetest). Kui meie jaoks piisaks ainult mõnest mündiviset, et priorist (eelnevast teadmisest) lahti ütelda, peaks meie prior sisaldama väikest kappat.</p>
<pre><code>Näiteks, mu prior on, et münt on aus (μ = 0.5; a = b), aga ma ei ole selles väga kindel. 
Niisiis ma arvan, et selle eelteadmise kaal võrdub sellega, kui ma oleksin näinud 8 mündiviske tulemust. 
Seega κ = 8, mis tähendab, et a = μκ = 4 and b = (1 − μ)κ = 4. 
Aga mis siis kui me tahame beta priorit, mille mood ω = 0.8 ja κ = 12? 
Siis saame valemist, et a = 9 ja b = 3. </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
m3 &lt;-<span class="st"> </span><span class="kw">map</span>(
    <span class="kw">alist</span>(
        dead <span class="op">~</span><span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">9</span>,p) ,  <span class="co"># binomial likelihood</span>
        p <span class="op">~</span><span class="st"> </span><span class="kw">dbeta</span>(<span class="dv">200</span>,<span class="dv">100</span>)     <span class="co"># beta prior</span>
), <span class="dt">data=</span><span class="kw">list</span>(<span class="dt">dead=</span><span class="dv">6</span>) )
<span class="co"># display summary of quadratic approximation</span>
<span class="kw">precis</span>( m3 )</code></pre></div>
<pre><code>##   Mean StdDev 5.5% 94.5%
## p 0.67   0.03 0.62  0.71</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">samples&lt;-<span class="kw">extract.samples</span>(m3)
<span class="kw">dens</span>(samples<span class="op">$</span>p)</code></pre></div>
<p><img src="main_files/figure-html/unnamed-chunk-222-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">HPDI</span>(samples<span class="op">$</span>p, <span class="dt">prob =</span> <span class="fl">0.95</span>) <span class="co">#highest density 95% at the center</span></code></pre></div>
<pre><code>##     |0.95     0.95| 
## 0.6161019 0.7209454</code></pre>
<p>Nagu näha on ka kitsa priori mõju üsna väika, isegi kui kui n=9.</p>
<div id="lopetuseks-veel-prioritest-uldiselt." class="section level4">
<h4><span class="header-section-number">11.2.1.1</span> Lõpetuseks veel prioritest üldiselt.</h4>
<p>Neid võib jagada kolmeks: mitteinformatiivsed, väheinformatiivsed ehk “regularizing” ja informatiivsed. Mitteinformatiivseid prioreid ei ole sisuliselt olemas ja neid on soovitav vältida. Väheinformatiivsed priorid kujutavad endast kompromissi: nad muudavad võimalikult vähe tõepärafunktsiooni kuju, aga samas piiravad seda osa parameetriruumist, kust MCMC ahelad posteeriori otsivad (mis on arvutuslikult soodne). Nende taga on filosoofiline eeldus, et teadlast huvitavad eelkõige tema enda andmed ja see, mida need ühe või teise hüpoteesi (parameetri väärtuse) kohta ütlevad. See eeldus on vaieldav aga kui selle järgi käia, siis kulub vähem mõttejõudu eelteadmiste mudelisse formaliseerimiseks. Vähemalt suured farmaatsiafirmad seda hoiakut ei jaga ja kulutavad usinalt oma miljoneid korralike informatiivsete priorite tootmiseks. Selles protsessis saavad kokku statistikud, teaduseksperdid ja psühholoogid, et inimkonna teadmisi võimalikult adekvaatselt vormida tõenäosusjaotustesse. Meie töötame siin siiski enamasti väheinformatiivsete prioritega, mis on hetkel moes. Aga teile oma teaduses soovitan siiralt arendada informatiivseid prioreid. Vähemalt nõnda toimides te mõtlete oma teaduse üle põhjalikult järele.</p>

<div id="refs" class="references">
<div>
<p>Bååth, Rasmus. 2013. “Bayesian First Aid.” <em>Tba</em>. <a href="tba" class="uri">tba</a>.</p>
</div>
<div>
<p>———. 2016. <em>Bayesboot: An Implementation of Rubin’s (1981) Bayesian Bootstrap</em>. <a href="https://CRAN.R-project.org/package=bayesboot" class="uri">https://CRAN.R-project.org/package=bayesboot</a>.</p>
</div>
<div>
<p>Bürkner, Paul-Christian. 2017. “brms: An R Package for Bayesian Multilevel Models Using Stan.” <em>Journal of Statistical Software</em> 80 (1): 1–28. doi:<a href="https://doi.org/10.18637/jss.v080.i01">10.18637/jss.v080.i01</a>.</p>
</div>
<div>
<p>Gabry, Jonah, and Tristan Mahr. 2017. <em>Bayesplot: Plotting for Bayesian Models</em>. <a href="http://mc-stan.org/bayesplot" class="uri">http://mc-stan.org/bayesplot</a>.</p>
</div>
<div>
<p>Gelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2014. <em>Bayesian Data Analysis</em>. Vol. 2. CRC press Boca Raton, FL.</p>
</div>
<div>
<p>Kruschke, John. 2014. <em>Doing Bayesian Data Analysis: A Tutorial with R, Jags, and Stan</em>. Academic Press.</p>
</div>
<div>
<p>Marwick, Ben, Carl Boettiger, and Lincoln Mullen. 2017. “Packaging Data Analytical Work Reproducibly Using R (and Friends).” <em>PeerJ Preprints</em> 5: e3192v1. doi:<a href="https://doi.org/10.7287/peerj.preprints.3192v1">10.7287/peerj.preprints.3192v1</a>.</p>
</div>
<div>
<p>McElreath, Richard. 2015. <em>Statistical Rethinking: A Bayesian Course with Examples in R and Stan</em>. CRC Press.</p>
</div>
<div>
<p>———. 2016. <em>Rethinking: Statistical Rethinking Book Package</em>.</p>
</div>
<div>
<p>Stan Development Team. 2016. <em>Rstanarm: Bayesian Applied Regression Modeling via Stan.</em> <a href="http://mc-stan.org/" class="uri">http://mc-stan.org/</a>.</p>
</div>
<div>
<p>Wickham, Hadley, Peter Danenberg, and Manuel Eugster. 2017. <em>Roxygen2: In-Line Documentation for R</em>. <a href="https://CRAN.R-project.org/package=roxygen2" class="uri">https://CRAN.R-project.org/package=roxygen2</a>.</p>
</div>
</div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="jata-meelde.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstats-tartu/lectures/edit/master/A02_inferential.Rmd",
"text": "Edit"
},
"download": ["main.pdf", "main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
